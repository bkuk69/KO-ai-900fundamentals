{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴 감지 및 분석Detecting and Analyzing Faces\n",
    "\n",
    "\n",
    "Computer Vision 솔루션은 종종 사람의 얼굴을 감지, 분석 또는 식별할 수 있는 인공지능(AI) 솔루션이 필요하다. 예를 들어, 소매업체 NorthWind Traders가 AI 서비스를 통해 매장을 모니터링하여 도움이 필요한 고객을 파악하고 직원들에게 도움을 지시하는 '스마트 스토어'를 구현하기로 결정했다고 가정합시다. 이를 달성하기 위한 한 가지 방법은 얼굴 감지 및 분석을 수행하는 것이다. 즉, 이미지에 얼굴이 있는지 확인하고, 얼굴의 특징을 분석하는 것이다.\n",
    "\n",
    "![A robot analyzing a face](./images/face_analysis.jpg)\n",
    "\n",
    "## Face 서비스를 통해 얼굴 감지 및 분석\n",
    "\n",
    "Northwind Traders회사에서 원하는 스마트 시스템은 고객의 얼굴 특징을 검지하고 분석할 수 있는 도구라고 가정하자. Microsoft Azure에서는 Azure Cognitive 서비스의 일종인 **Face**를 활용하여 이것을 해결할 수 있다. \n",
    "\n",
    "### Cognitive 서비스 리소스 생성하기\n",
    "\n",
    "Azure 구독에서 **Cognitive Services** 리소스를 생성하자.\n",
    "\n",
    "> **알림**: 만일 이미 Cognitive 서비스 리소스를 이미 가지고 있다면 Azure 포털에 있는 **최식 리소스**에 있는 리소스를 열어서 키와 엔드포인트를 복사해서 아래 셀에 붙여 넣으면 된다. 아니면 아래 순서로 만들면 된다\n",
    "\n",
    "1. 브라우저의 새로운 탭을 열고, Azure portal( https://portal.azure.com)을 입력하고 , Microsoft계정으로 로그인한다..\n",
    "2. **&#65291;리소스 만들기** 버튼을 클릭하고, *Cognitive Services* 서비스를 찾은 다음, **Cognitive Services** 리소스를 다음과 같은 내용으로 생성한다.\n",
    "    - **이름**: *유일한 이름을 입력한다(가능하면 영문과 숫자사용)*.\n",
    "    - **구독**: *Azure 구독선택*.\n",
    "    - **위치**: *가능한 위치(한국 중부 추천)*:\n",
    "    - **가격책정계층**: 표준 S0\n",
    "    - **리소스 그룹**: *원하는 유리한 이름(가능하면 영문과 숫자사용)*.\n",
    "3. 배포가 완료될 때까지 기다린다. 그런 다음 Cognitive Services 리소스로 이동하여 **개요* 페이지에서 링크를 클릭하여 서비스 키를 관리한다. 클라이언트 응용 프로그램에서 Cognitive Services 리소스에 연결하려면 엔드포인트과 키가 필요하다.\n",
    "\n",
    "### Cognitive Services 리소스에 있는 키와 엔드포인트 가져오기\n",
    "\n",
    "Cgnitive Services 리소스를 사용하기 위해서는, 클라이언트 응용프로그램에서는 엔드포인트와 인증 키가 필요합니다.client applications need its endpoint and authentication key:\n",
    "\n",
    "1. Azure portal에서, Cgnitive Services 리소스를 선택하고 **키 및 엔트포인트** 페이지를 선택한 다음 **키1** 을 복사하여 아래의 **YOUR_COG_KEY**.를 붙여 넣는다.\n",
    "2. 리소스에 있는 **엔드포인트** 를 복사해서 아래의 **YOUR_COG_ENDPOINT**.에 붙여 넣는다. \n",
    "3. 셀을 선택한 다음 셀 왼쪽에있는 **셀 실행**(&#9655;) 버튼을 클릭하여 아래 코드를 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693964655
    }
   },
   "outputs": [],
   "source": [
    "cog_key = 'YOUR_COG_KEY'\n",
    "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cognitive Services 리소스에서 Face 서비스를 이용하기 위해서는 Azure Cognitive Services Face 패키지를 설치해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install azure-cognitiveservices-vision-face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Cognitive 서비스 리소스와 설치된 SDK 패키지를 가지고 있으므로 가게 있는 사람 얼굴을 검지하기 위해 Face 서비스를 이용할 수 있다. \n",
    "예를 확인하기 위해 아래 셀의 코드를 실행해보라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970079
    }
   },
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from python_code import faces\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# 얼굴 검지 클라이언트를 만든다.\n",
    "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# 이미지를 연다.\n",
    "image_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# 얼굴을 검지한다.\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# 얼굴을 나타낸다(python_code/faces.py의 코드를 이용한다)\n",
    "faces.show_faces(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검지된 얼굴들은 각각 유일한 ID가 할당되고 응용프로그램은 감지된 개별 얼굴을 구분할 수 있다.\n",
    "\n",
    "아래 셀을 실행해서 쇼핑하고 있는 고객들의 얼굴에 대한 ID값을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970447
    }
   },
   "outputs": [],
   "source": [
    "# 이미지를 연다.\n",
    "image_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# 얼굴을 감지한다.\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# 얼굴들을 나타낸다.(ython_code/faces.py에 있는 코드를 이용한다)\n",
    "faces.show_faces(image_path, detected_faces, show_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴의 속성들을 분석한다.\n",
    "\n",
    "Face리소스는 단지 얼굴을 검지하는 것 외의 더 많은 일들을 수행할 수 있다. 얼굴 특징을 분석할 수 있고 나이와 감정상태에 등에 대한 설명을 제공한다. 예를들면 아래의 코드를 실행하여 쇼핑객의 얼굴 속성들을 분석해보자.For example, run the code below to analyze the facial attributes of a shopper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693971321
    }
   },
   "outputs": [],
   "source": [
    "# 이미지를 연다\n",
    "image_path = os.path.join('data', 'face', 'store_cam1.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# 얼굴을 감지하고 얼굴 특성을 지정한다.\n",
    "attributes = ['age', 'emotion']\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
    "\n",
    "# 얼굴들과 속성값들을 나타낸다(python_code/faces.py에 있는 코드를 이용한다).\n",
    "faces.show_face_attributes(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "이미지에있는 고객의 감정 상태 점수를 바탕으로 쇼핑 경험에 대한 행복정도를 판정할 수 있다.\n",
    "\n",
    "## 비슷한 얼굴 찾기  \n",
    "\n",
    "검지된 각 얼굴에 대한 얼굴 ID 값들은 각 얼굴들끼리 일치도를 알아보는데 사용된다.이런 ID를 이용하여 이전에 검지된 얼굴과 비교하는데 사용되고 비슷한 특징이 있는 얼굴들을 찾는데 사용된다.\n",
    "\n",
    "예를들면 아래의 셀에 있는 코드를 싷행하여 하나의 사진에 있는 쇼핑객과 다른 사진에 있는 모습을 비교하여 일치하는 얼굴을 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693972555
    }
   },
   "outputs": [],
   "source": [
    "# 이미지 1에 있는 첫번째 울글의 ID를 가져온다.\n",
    "image_1_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_1_stream = open(image_1_path, \"rb\")\n",
    "image_1_faces = face_client.face.detect_with_stream(image=image_1_stream)\n",
    "face_1 = image_1_faces[0]\n",
    "\n",
    "# 두번째 이미지에 있는 Face ID 값들을 가져온다.\n",
    "image_2_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_2_stream = open(image_2_path, \"rb\")\n",
    "image_2_faces = face_client.face.detect_with_stream(image=image_2_stream)\n",
    "image_2_face_ids = list(map(lambda face: face.face_id, image_2_faces))\n",
    "\n",
    "# 이미지 1에 있는 얼굴과 비슷한 얼굴이 이미지 2에 있는는지 찾는다.\n",
    "similar_faces = face_client.face.find_similar(face_id=face_1.face_id, face_ids=image_2_face_ids)\n",
    "\n",
    "# 이미지 1에 있는 얼굴과 비슷한 얼굴을 이미지 2에서 찾아서 나타낸다(python_code/face.py에 있는 코드를 사용한다).\n",
    "faces.show_similar_faces(image_1_path, face_1, image_2_path, image_2_faces, similar_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 인식(Facial Regcognition)하기\n",
    "\n",
    "지금까지 여러분은 Face서비스로 얼굴과 얼굴의 특징을 감지할 수 있고, 서로 비슷한 두 얼굴을 식별할 수 있다는 것을 봤다. 특정 사람의 얼굴을 인식하도록 Face를 학습시키는 *얼굴 인식(Face Recognition)* 솔루션을 구현하면 한 단계 더 나아갈 수 있다. 이는 소셜 미디어 응용 프로그램에서 친구의 사진을 자동으로 태그하거나 생체 인식 확인 시스템의 일부로 얼굴 인식을 사용하는 등 다양한 시나리오에서 유용할 수 있다.\n",
    "이런 작업들이 어떻게 일어나는지 살펴보기 위해 Northwind Traders 회사가 얼굴 인식서비스를 이용하여 IT 부서의 권한이 있는 직원만 보안 시스템에 액세스 하도록 하는 시스템을 만들고 싶다고 가정한다.\n",
    "\n",
    "권한이 있는 직원을 대표할 수 있는 *직원그룹*을 만드는 작업부터 시작해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693973492
    }
   },
   "outputs": [],
   "source": [
    "group_id = 'employee_group_id'\n",
    "try:\n",
    "    # Delete group if it already exists\n",
    "    face_client.person_group.delete(group_id)\n",
    "except Exception as ex:\n",
    "    print(ex.message)\n",
    "finally:\n",
    "    face_client.person_group.create(group_id, 'employees')\n",
    "    print ('Group created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*직원 그룹*이 존재하므로 해당 그룹에 포함시키기 원하는 직원들을 그룹에 포함시킨다.그리고 나서 각 직원들에 대한 여러종류의 사진들을 등록하여 Face서비스가 각 사람들의 독특한 특징들에 대한 것들을 학습하도록한다. 이상적인 것은 특정사람이 다양한 포즈와 서로다른 감정을 나타내는 사진이 필요하다.\n",
    "우리는 Wendell이라는 한명의 직원을 등록하고 해당 직원에 대한 여러 종류의 사진을 등록할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693976898
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# 직원(Wendell)을 그룹에 추가한다.\n",
    "wendell = face_client.person_group_person.create(group_id, 'Wendell')\n",
    "\n",
    "# Wendel/에 대한 사진들을 가져온다\n",
    "folder = os.path.join('data', 'face', 'wendell')\n",
    "wendell_pics = os.listdir(folder)\n",
    "\n",
    "# 사진들을 등록한다.\n",
    "i = 0\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for pic in wendell_pics:\n",
    "    # 직원 그룹이 있는 사람에게 각 사진들을 추가한다.\n",
    "    img_path = os.path.join(folder, pic)\n",
    "    img_stream = open(img_path, \"rb\")\n",
    "    face_client.person_group_person.add_face_from_stream(group_id, wendell.person_id, img_stream)\n",
    "\n",
    "    # 각 이미지들을 표시한다.\n",
    "    img = Image.open(img_path)\n",
    "    i +=1\n",
    "    a=fig.add_subplot(1,len(wendell_pics), i)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가된 직원과 사진들을 등록하였다면 Face를 학습하여 각 사진을 인식하도록 할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693977046
    }
   },
   "outputs": [],
   "source": [
    "face_client.person_group.train(group_id)\n",
    "print('Trained!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 학습된 모델을 사용하여 이미지에 있는 얼굴들을 구분하는데 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693994820
    }
   },
   "outputs": [],
   "source": [
    "# 두번째 이미지에 있는 얼굴 ID를 가져온다.\n",
    "image_path = os.path.join('data', 'face', 'employees.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "image_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "image_face_ids = list(map(lambda face: face.face_id, image_faces))\n",
    "\n",
    "# 인식한 얼굴이름들을 가져온다\n",
    "face_names = {}\n",
    "recognized_faces = face_client.face.identify(image_face_ids, group_id)\n",
    "for face in recognized_faces:\n",
    "    person_name = face_client.person_group_person.get(group_id, face.candidates[0].person_id).name\n",
    "    face_names[face.face_id] = person_name\n",
    "\n",
    "# 인식한 알굴들을 나타낸다.\n",
    "faces.show_recognized_faces(image_path, image_faces, face_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 심화 학습\n",
    "\n",
    "Face 인지 서비스에 대하여 더 많이 알고 싶다면 [Face documentation](https://docs.microsoft.com/azure/cognitive-services/face/) 를 참조하라.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
