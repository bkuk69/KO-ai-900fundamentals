{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 분류하기(Classification)\n",
        "\n",
        "*Computer Vision* Cognitive 서비스는 이미지를 작업할 때 유용하게 사전 제작된 모델을 제공하지만 종종 컴퓨터 비전을 위한 자신만의 모델을 교육해야 한다. 예를 들어, Northwind Traders 소매 회사가 계산대에서 카메라로 찍은 이미지를 기반으로 고객이 구매하고자 하는 식료품 품목을 식별하는 자동 계산 시스템을 생성하려고 한다고 가정해 보자. 이렇게 하려면 이미지를 분류하여 구입하려는 항목을 식별할 수 있는 분류 모델을 교육해야 한다.\n",
        "\n",
        "![A robot holding a clipboard, classifying pictures of an apple, a banana, and an orange](./images/image-classification.jpg)\n",
        "\n",
        "Azure에서 ***Custom Vision*** Cognitive 서비스를 사용하여 이미 존재하는 이미를 기초로하여 이미지 분류모델을 학습시킬 수 있다. 이미지 분류 모델을 생성하기 위해서는 두가지 요소가 있다. 첫번째로 이미 존재하는 이미지를 사용하여 각기 다른 클래스로 인지하도록 모델을 학습시켜야 한다. 그리고 나서 모델이 학습하였다면 응용프로그램이 이용하도록 서비스를 게시해야 한다. \n",
        "\n",
        "## Custom Vision 리소스 만들기\n",
        "\n",
        "Custom Vision 서비스를 사용하려면 모델을 *training* 하는 데 사용할 수 있는 Azure 리소스와 애플리케이션을 위해 모델을 *게시*할 수 있는 리소스가 필요하다. 두 작업 중 하나 또는 둘 다에 대한 리소스는 일반적인 **Cognitive 서비스** 리소스 또는 특별한 **CustomVision** 리소스가 될 수 있다. 이러한 각 작업에 대해 동일한 Cognitive 서비스 리소스를 사용하거나, 각 작업에 대해 서로 다른 리소스(동일한 지역)를 사용하여 비용을 별도로 관리할 수 있다.\n",
        "\n",
        "새로운 **Custom Vision** 리소스를 만들기 위해서는 다음과 같은 순서로 수행하면 된다.\n",
        "\n",
        "1. 새 브라우저 탭에서 [https://portal.azure.com](https://portal.azure.com)에서 Azure 포털을 열고 Azure 구독과 연결된 Microsoft 계정을 사용하여 로그인한다.\n",
        "2. **&#65291;리소스 만들기** 버튼을 선택하고, *Custom Vision*을 검색한 뒤에 다음과 같이 **Custom Vision** 리소스를 생성한다:\n",
        "    - **만들기 옵션**: 둘 다\n",
        "    - **구독**: *Azure 구독 옵션*\n",
        "    - **리소스 그룹**: *유일한 이름으로 리소스 그룹 생성하기*\n",
        "    - **이름**: *유일한 이름(영문과 숫자 적용)*\n",
        "    - **학습 위치**: *가능한 위치 선택*\n",
        "    - **교육 가격 책정 계층**: F0\n",
        "    - **예측 위치**: *학습위치와 동일한 지역 선택*\n",
        "    - **예측 가격 책정위치**: F0\n",
        "\n",
        "    > **알림**: 여러분들이 이미 F0 Custom Vision서비스를 사용하고 있다면 여기서는 **S0**을 선택함.\n",
        "\n",
        "3. 리소스가 생성되길 기다리고 두개의 Custom Vision 리소스가 생성 되어야 하는데 하나는 학습을 위해서 이고 하나는 예측을 위해서이다. 이런 것들은 여러분이 생성한 리소스 그룹에 종속되어 보여진다.\n",
        "\n",
        "## Custom Vision 프로젝트 만들기\n",
        "\n",
        "객체 감지 모델을 학습시키기 위해 학습 리소스를 바탕으로 하여 Custom Vision 객체를 생성하여야 한다.이렇게 하기 위해서는 Custom Vision 포털을 사용하게 될 것이다.\n",
        "\n",
        "1. 학습 이미지 파일을 다운로드 하여 합축을 해제한다.( https://aka.ms/fruit-images.)\n",
        "2. 브라우저의 다릅 탭을 열고, Custom Vision portal 사이트 [https://customvision.ai](https://customvision.ai) 를 입력한다. 입력 창에 Azure 구독에 사용된 Microsoft 계정 정보를 입력하고 서비스 계약서에 동의한다..\n",
        "3. Custom Vision 포털에서, 다음과 같은 내용으로 새로운 프로젝트를 입력한다.\n",
        "    - **Name**: Grocery Checkout\n",
        "    - **Description**: 채소에 대한 이미지 분류\n",
        "    - **Resource**: *앞에서 만든 Custom Vision 리소스*\n",
        "    - **Project Types**: Classification\n",
        "    - **Classification Types**: Multiclass (single tag per image)\n",
        "    - **Domains**: Food\n",
        "4.  **\\[+\\] Add images**를 클릭하고 앞에서 압축을 해제한 **apple** 폴더에 있는 모든 파일을 선택한다. 이미지를 업로드하고 나서 이미지에 *apple*로 태그를 단다.\n",
        "\n",
        "![Upload apple with apple tag](./images/upload_apples.jpg)\n",
        "   \n",
        "5. 앞에서와 같은 순서로 **banana** 폴더의 이미지에 태그를 *banana*로 달고 , **orange** 폴더에 있는 이미지들에는*orange*라는 태그를 부여한다.\n",
        "6. Custom Vision 프로젝트 내에 업로드한 이미지들을 확인해본다-각 분야마다 15개의 이미지들이 존재한다.예를들면 다음과 같다.\n",
        "\n",
        "![Tagged images of fruit - 15 apples, 15 bananas, and 15 oranges](./images/fruit.jpg)\n",
        "    \n",
        "7. Custom Vision 프로젝트에서 이미지들 위에 있는 **Train**을 클릭하여 태그가 된 이미지들 이용하여 분류 모델을 학습시킨다. **Quick Training** 옵션을 클릭하고 학습 순서가 끝나기를 기다린다(이 작업은 1분 이상 걸릴 수 있다).\n",
        "8. 모델이 학습되었다면 *Precision*, *Recall*, 그리고 *AP* 성능 Metrics를 확인한다 - 이런 값들은 분류 모델의 정확도를 예측하는데 사용되며 모두 높게 나와야 좋다.\n",
        "\n",
        "## 모델을 테스트하기\n",
        "\n",
        "응용 프로그램에 사용하기 위해 게시하는 작업 전에 모델을 테스트해보아야 한다.\n",
        "\n",
        "1. 성능 Metrics위에 있는 **Quick Test**를 클릭한다.\n",
        "2. **Image URL** 상자에서, `https://aka.ms/apple-image`라 입력하고 &#10132; 를 클릭한다.\n",
        "3. 모델에 의해 예측된 결과를 확인한다-아래와 같이 *apple*에 대한 Probability 점수가 가장 높아야 한다:\n",
        "\n",
        "![An image with a class prediction of apple](./images/test-apple.jpg)\n",
        "\n",
        "4. **Quick Test** 창을 닫는다.\n",
        "\n",
        "## 이미지 분류 모델을 게시하고 사용하기\n",
        "\n",
        "이제 학습시킨 모델을 게시하고 클라이언트 응용프로그램에서 사용할 수 있게 되었다.\n",
        "\n",
        "9. 다음과 같은 내용을 입력하고 **&#128504; Publish**를 클릭하여 학습시킨 모델을 게시한다.\n",
        "    - **Model name**: groceries\n",
        "    - **Prediction Resource**: *앞에서 생성한 예측 리소스*.\n",
        "10. 게시후에 프로젝트의 설정을 확인하기 위해 **Performance**페이지의 윈쪽 오른편에 있는 *settings* (&#9881;) 아이콘을 클릭한다. 그런 후 (왼쪽에 있는)**General** 에서, **Project Id**를 복사하여 아래의 코드셀에 붙여 넣는다(**YOUR_PROJECT_ID**를 대체한다).\n",
        "\n",
        "![Project ID in project settings](./images/cv_project_settings.jpg)\n",
        "\n",
        "> _**Note**: 이 학습이 초기에 **Custom Vision** 리소스를 사용하는 대신 **Cognitive Services** 리소스를 사용했다면, 프로젝트 설정의 오른편에 있는 키와 엔트포인트를 복사해서 아래의 코드셀에 붙여 넣고 결과를 확인하기 위해서 실행한다.그렇지 않으면, Custom Vision 예측 리소스에 대한 키와 엔드포인트를 얻기 위해 아래와 같은 작업을 완료한다. \n",
        "\n",
        "11. A**Project Settings** 설정 페이지의 위쪽 왼편에 있는 *Projects Gallery* (&#128065;) 아이콘을 클릭하여 Custom Vision 포털 홈페이지로 이동하면 프로젝트 목록이 나타난다.\n",
        "12. Custom Vision 포털 홈페이지에서 윗쪽 오른편에서  *settings* (&#9881;) 아이콘을 클릭하여 Custom Vision 서비스에 대한 설정을 본다. 그리고 나서 **Resources** 밑에 *prediction* 리소스를 클릭하고 resource (학습리소스가 <u>아님</u> ) **키**와 **엔드포인트**값을 복사해서 아래의 **YOUR_KEY** 와 **YOUR_ENDPOINT**를 대체한다.\n",
        "\n",
        "![Prediction resource key and endpoint in custom vision settings](./images/cv_settings.jpg)\n",
        "\n",
        "13. 프로젝트 ID, 키, 엔드포인트값 변수 값을 설정한 후에 **Run cell** (&#9655;) 버튼(셀의 왼편에 있음)을 클릭하여 실행한다."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'YOUR_PROJECT_ID'\n",
        "cv_key = 'YOUR_KEY'\n",
        "cv_endpoint = 'YOUR_ENDPOINT'\n",
        "\n",
        "model_name = 'groceries' # 이 모델 이름은 모델 게시작업때 설정한 이름과 대소문자까지 일치해야 한다!\n",
        "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599691949340
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python에서 Custom Vision 서비스를 사용하기 위해서는 Azure Cognitive Services Custom Vision 패키지를 설지해야 한다."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-cognitiveservices-vision-customvision"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 Custom Vision 클라이언트가  키와 엔드포인트를 사용하여 만든 Custom Vision 분류 모델에 연결힐 수 있다.\n",
        "\n",
        "게시한 모델을 사용하여 테스트 이미지를 잘 분석하는지 알아보기 위해 아래와같은 코드를 실행한다.\n",
        "\n",
        "> **Note**: 코드의 너무 자세한 내용에 대해서 걱정하지 말라. 이건 Computer Vision SDK for Python를 사용하여 /data/image-classification/test-fruit폴더에 있는 각이미지에 대한 분류 예측을 위한 것이다. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
        "from msrest.authentication import ApiKeyCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# data/vision/test 폴더에 있는 이미지 들을 가져온다.\n",
        "test_folder = os.path.join('data', 'image-classification', 'test-fruit')\n",
        "test_images = os.listdir(test_folder)\n",
        "\n",
        "# 예측 서비스의 인스턴스를 생성한다.\n",
        "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\n",
        "custom_vision_client = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)\n",
        "\n",
        "# 결과를 화면에 표시하도록 그림을 생셩한다.\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "# 이미지를 가져와서 각 이미지에 대한 예측 분류값을 보여준다.\n",
        "print('Classifying images in {} ...'.format(test_folder))\n",
        "for i in range(len(test_images)):\n",
        "    # 이미지를 앨고 Custom Vision 모들을 사용하여 분류하도록 준비한다.\n",
        "    image_contents = open(os.path.join(test_folder, test_images[i]), \"rb\")\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\n",
        "    # 예측 값은 각 이미지 태그에 대한 예측값을 호함하고 확률을 내림차순으로 정리해서 보여준다.\n",
        "    prediction = classification.predictions[0].tag_name\n",
        "    # 예측 클래스가 포함된 이미지를 나타낸다.\n",
        "    img = Image.open(os.path.join(test_folder, test_images[i]))\n",
        "    a=fig.add_subplot(len(test_images)/3, 3,i+1)\n",
        "    a.axis('off')\n",
        "    imgplot = plt.imshow(img)\n",
        "    a.set_title(prediction)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599692327514
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다행히 여러분의 이미지 분류 모델은 정확하게 이미지 있는 채소를 바르게 찾아 낸다.\n",
        "\n",
        "## 추가 학습\n",
        "\n",
        "Custom Vision 서비스는 이 학습에서 본 것들 보다 너 능률적인 것으로 보여준다. 예를 들면 Custom Vision서비스를 사용하여 *객체 감지* 모델을 생성하는데 Custom Vision 모델을 사용할 수 있다(이것은 이미지 내에 있는 객체들을 구분할 뿐만 아니라 이미지에 포함되어 있는 개체의 위치를 보여주는 *튀어오르는 상자*를 구분할 수 있다.\n",
        "\n",
        "Custom Vision cognitive 서비스에 대해서 더 많은 것을 알고 싶다면 , [Custom Vision documentation](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home)를 참조하면 된다."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}